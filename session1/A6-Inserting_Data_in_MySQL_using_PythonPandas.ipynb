{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting and Reading data from MySQL using Pandas\n",
    "\n",
    "First let's start with a basic piece of code that fetches the data that we want to insert in the database. For our example, we will get the data about the Citibike stations, using the correspoding API call provided by the Citibike website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo pip3 install -U -q PyMySQL sqlalchemy sql_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the data from the Citibike API\n",
    "\n",
    "# This gives information for each station that remains stable over time\n",
    "url_stations = \"https://gbfs.citibikenyc.com/gbfs/en/station_information.json\"\n",
    "# This gives the live status of all the stations (e.g., bikes available etc)\n",
    "url_status = \"https://gbfs.citibikenyc.com/gbfs/en/station_status.json\"\n",
    "\n",
    "# We fetch for now just the time-invariant data\n",
    "results = requests.get(url_stations).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only need a subset of the data in the JSON returned by the Citibike API, so we keep only what we need\n",
    "data = results[\"data\"][\"stations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the 'rental methods' columns,\n",
    "# as they contains multiple values and\n",
    "# we cannot insert lists in a database cell.\n",
    "df.drop(\n",
    "    [\"rental_methods\", \"eightd_station_services\", \"rental_uris\"],\n",
    "    axis=\"columns\",\n",
    "    inplace=True,\n",
    ")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a Pandas Dataframe in a MySQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "conn_string = \"mysql+pymysql://{user}:{password}@{host}/\".format(\n",
    "    host=\"db.ipeirotis.org\", user=\"student\", password=\"dwdstudent2015\"\n",
    ")\n",
    "\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have connected successfully, we need to create our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to create a database\n",
    "# In this example, we will try to create the (existing) database \"public\"\n",
    "# But in general, we can give any name to the database\n",
    "db_name = \"public\"\n",
    "create_db_query = (\n",
    "    f\"CREATE DATABASE IF NOT EXISTS {db_name} DEFAULT CHARACTER SET 'utf8'\"\n",
    ")\n",
    "\n",
    "# Create a database\n",
    "engine.execute(create_db_query)\n",
    "\n",
    "# And lets switch to the database\n",
    "engine.execute(f\"USE {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid conflicts between people writing in the same database, we add a random suffix in the tables\n",
    "# We only create the variable once while running the notebook\n",
    "import uuid\n",
    "\n",
    "if \"suffix\" not in globals():\n",
    "    suffix = str(uuid.uuid4())[:8]\n",
    "print(suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Table and Store Data in Database using the `to_sql` command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the table where we will store our data. Since we already have the data in a Pandas DataFrame, it is very easy to put the data in a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = f\"Stations_{suffix}\"\n",
    "# Create a table\n",
    "# See http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html for the documentation\n",
    "\n",
    "# This step is optional, but it is good practice to define explicitly the\n",
    "# data types before storing things in a database. In many cases, this can be ommitted, though.\n",
    "\n",
    "dtype = {\n",
    "    \"legacy_id\": sqlalchemy.types.SMALLINT(),\n",
    "    \"station_id\": sqlalchemy.types.SMALLINT(),\n",
    "    \"region_id\": sqlalchemy.types.SMALLINT(),\n",
    "    \"external_id\": sqlalchemy.types.VARCHAR(50),\n",
    "    \"lat\": sqlalchemy.types.Float,\n",
    "    \"lon\": sqlalchemy.types.Float,    \n",
    "    \"short_name\": sqlalchemy.types.VARCHAR(10),\n",
    "    \"name\": sqlalchemy.types.VARCHAR(60),\n",
    "    \"station_type\": sqlalchemy.types.VARCHAR(10),\n",
    "    \"capacity\": sqlalchemy.types.SMALLINT(),\n",
    "    \"electric_bike_surcharge_waiver\": sqlalchemy.types.BOOLEAN,\n",
    "    \"eightd_has_key_dispenser\": sqlalchemy.types.BOOLEAN,\n",
    "    \"has_kiosk\": sqlalchemy.types.BOOLEAN,\n",
    "}\n",
    "\n",
    "\n",
    "df.to_sql(\n",
    "    name=table_name,\n",
    "    schema=db_name,\n",
    "    con=engine,\n",
    "    if_exists=\"replace\",\n",
    "    index=False,\n",
    "    dtype=dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we have the data in the table, we also specify a primary key\n",
    "# If we had FOREIGN KEYS we can add them in the same way\n",
    "add_key_query = f\"ALTER TABLE {table_name} ADD PRIMARY KEY(station_id)\"\n",
    "print(add_key_query)\n",
    "engine.execute(add_key_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from a SQL Database in Python using the `read_sql` command in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can similarly read from the database using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {db_name}.{table_name}\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_sql(query, con=engine)\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Data from Database to CSV or Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And remember that from Pandas it is also possible to export in other formats, such as Excel of CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The necessary library to write in Excel\n",
    "# !sudo pip3 install -U openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_excel(\"citibike.xlsx\")\n",
    "df2.to_csv(\"citibike.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's clean up and delete the table that we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_table_query = f\"DROP TABLE IF EXISTS {db_name}.{table_name}\"\n",
    "print(drop_table_query)\n",
    "engine.execute(drop_table_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "The `url_status = 'https://gbfs.citibikenyc.com/gbfs/en/station_status.json'` URL contains the status of the stations. Write code that reads the results from that API call, and then stores the data in a separate table. Add a \"foreign key\" constraint from the Status table to the Stations table that we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
